{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "k_Jw-OrfM5e9",
        "xDBv161WANsX"
      ],
      "mount_file_id": "14gJYQXUqKn_l_LjPK9OZYm_B1Lve0PQz",
      "authorship_tag": "ABX9TyMFxfGTEBtkRWFxvUdFJINH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattshu0410/Peripheral-Blood-Deep-Learning/blob/main/YOLOv5_Crop_Out_WBC_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import PIL\n",
        "import numpy as np\n",
        "import os\n",
        "import ast\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "d4dNuwXMEEUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crop out BCCD WBC w/ YOLOv5s\n",
        "\n",
        "This section aims to cut out all WBC out of the BCCD dataset using YOLOv5. This can then be categorised into WBC types by a hematologist. This will then be used as an independent test set to assess the effectiveness of the WBC classifier trained on the WBC dataset from Acevedo et. al."
      ],
      "metadata": {
        "id": "C1ajjFWcrlAm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_siMhu3pT2d"
      },
      "outputs": [],
      "source": [
        "# Gathers BCCD dataset\n",
        "!git clone 'https://github.com/Shenggan/BCCD_Dataset.git'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies for YOLOv5\n",
        "!pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
      ],
      "metadata": {
        "id": "Rw-ndqAvuE8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clones repository containing models from Git Repo: https://github.com/ultralytics/yolov5\n",
        "!git clone  'https://github.com/ultralytics/yolov5.git'"
      ],
      "metadata": {
        "id": "p2bT2bBOuxQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs YOLOv5s and stores all annotations as text\n",
        "!python /content/yolov5/detect.py --source /content/BCCD_Dataset/BCCD/JPEGImages --weights \"/content/4-01-2022-artemis.pt\" --save-txt "
      ],
      "metadata": {
        "id": "q2tPxGcpu8bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that cropps out all white blood cells for a particular image, takes a list of dictionaries i.e. records\n",
        "# e.g. [{'category_id': 2, 'x': 0.414062, 'y': 0.459375, 'w': 0.28125, 'h': 0.385417, 'image_id': 'BloodImage_00300'}, {...}, {...}]\n",
        "def image_crop(bbox_dict, export_path):\n",
        "  image_id = bbox_dict[0]['image_id']\n",
        "  image = PIL.Image.open(f'/content/BCCD_Dataset/BCCD/JPEGImages/{image_id}.jpg')\n",
        "  for i, bbox in enumerate(bbox_dict):\n",
        "    image_w, image_h = image.size\n",
        "    image_array = np.array(image)\n",
        "    x,y,w,h = int(bbox_dict[i]['x']*image_w), int(bbox_dict[i]['y']*image_h), int(bbox_dict[i]['w']*image_w), int(bbox_dict[i]['h']*image_h)\n",
        "    w=h=max(w,h) # We want square crops that include the whole WBC\n",
        "    x_i, x_f, y_i, y_f  = x-w/2, x+w/2, y-h/2, y+h/2\n",
        "    # If a square bounding box reaches outside the image, this will shift the limits back into the image\n",
        "    if x_i<0:\n",
        "      x_f = x_f-x_i\n",
        "      x_i = 0\n",
        "    if x_f>image_w:\n",
        "      x_i = x_i-(x_f-image_w)\n",
        "      x_f = image_w\n",
        "    if y_i<0:\n",
        "      y_f = y_f-y_i\n",
        "      y_i = 0\n",
        "    if y_f>image_h:\n",
        "      y_i = y_i-(y_f-image_h)\n",
        "      y_f = image_h\n",
        "    crop_img=image_array[int(y_i):int(y_f), int(x_i):int(x_f)]\n",
        "    try:\n",
        "      im = PIL.Image.fromarray(crop_img)\n",
        "      im = im.resize((224,224))\n",
        "      im.save(os.path.join(export_path, f'{image_id}_{i}.png')) # File naming is {image_id} + {i}th WBC cropped\n",
        "    except:\n",
        "      print(f'{image_id} was omitted')\n",
        "\n"
      ],
      "metadata": {
        "id": "YxtjPhGUGmIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_path = '/content/yolov5/runs/detect/exp/labels/'\n",
        "export_path = '/content/BCCD_cropped_wbc/'\n",
        "wbc=[]\n",
        "\n",
        "# Extracts all bounding boxes that are white blood cells\n",
        "for filename in os.listdir(label_path):\n",
        "  with open(os.path.join(label_path, filename)) as file:\n",
        "    # Creates a dataframe with all the bounding boxes found in this image\n",
        "    df = pd.read_csv(file, \n",
        "                     delim_whitespace=True, \n",
        "                     header = None,\n",
        "                     names =['category_id', 'x', 'y', 'w', 'h'])\n",
        "    df['image_id'] = filename.rstrip('.txt')\n",
        "    # Adds to a list of dictionaries containing all WBC across all images\n",
        "    wbc += df[df.category_id == 2].to_dict('records')\n"
      ],
      "metadata": {
        "id": "lyr4n19Lvujt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe of image_id and \n",
        "wbc_df = pd.DataFrame.from_dict(wbc)\n",
        "\n",
        "# Runs crop on each image\n",
        "for image_id in set(wbc_df['image_id'].tolist()):\n",
        "  bbox_dict = wbc_df[wbc_df['image_id']==image_id].to_dict('records')\n",
        "  image_crop(bbox_dict)\n",
        "\n"
      ],
      "metadata": {
        "id": "p7OKp7g_DvdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r '/content/BCCD_cropped_wbc.zip' '/content/BCCD_cropped_wbc'"
      ],
      "metadata": {
        "id": "kOtEpjiP7-3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crop out Acevedo et. al. dataset WBC w/ YOLOv5s\n",
        "\n",
        "The following section aims to crop out all WBC from the data published by Acevedo et. al.\n",
        "\n",
        "Dataset: https://www.sciencedirect.com/science/article/pii/S2352340920303681\n",
        "\n"
      ],
      "metadata": {
        "id": "4ClB56i42RA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/PBC_dataset_normal_DIB.zip'"
      ],
      "metadata": {
        "id": "5yCZIJdH3JUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/Colab Notebooks/4-01-2022-artemis.pt' '/content'"
      ],
      "metadata": {
        "id": "OsJ1Rt2waGFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs YOLOv5s and stores all annotations as text\n",
        "wbc_type = ['basophil', 'eosinophil', 'erythroblast', 'ig', 'lymphocyte', 'monocyte', 'neutrophil', 'platelet']\n",
        "for wbc in wbc_type:\n",
        "  !python /content/yolov5/detect.py --source /content/PBC_dataset_normal_DIB/{wbc} --weights \"/content/4-01-2022-artemis.pt\" --save-txt --project runs/detect/{wbc} --classes 2 --nosave --exist-ok"
      ],
      "metadata": {
        "id": "ch_E-eZ53mGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cropping out Images (Size not Considered)\n",
        "\n",
        "In many cases the YOLOv5s object detection model manages to pick out WBC on the border of the image. However, given we are dealing with a clean dataset where each image's label corresponds to a single cell that is largest and closest to the centre, we will use this as our rule for choosing the primary bounding box to cut out. If both conditions are not met by a single bounding box we will call for a manual check."
      ],
      "metadata": {
        "id": "2C5IoxfaBvS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crops the main white blood cell from the image based on given bounding boxes from YOLOV5s\n",
        "def single_crop(bbox_dict, wbc):\n",
        "  image_id = bbox_dict[0]['image_id']\n",
        "  image = PIL.Image.open(f'/content/PBC_dataset_normal_DIB/{wbc}/{image_id}.jpg')\n",
        "  image_w, image_h = image.size\n",
        "  image_array = np.array(image)\n",
        "  main_bbox = {}\n",
        "  # YOLOV5s model detects multiple bounding boxes.\n",
        "  # This automatically chooses the main bounding box to be one with the largest size and closest to the centre\n",
        "  # It will throw a warning when either of these conditions are not met but will choose closest to the centre\n",
        "  if len(bbox_dict)==1:\n",
        "    i=0\n",
        "    x,y,w,h = int(bbox_dict[i]['x']*image_w), int(bbox_dict[i]['y']*image_h), int(bbox_dict[i]['w']*image_w), int(bbox_dict[i]['h']*image_h)\n",
        "    main_bbox = {\n",
        "          'x': x,\n",
        "          'y': y,\n",
        "          'w': w,\n",
        "          'h': h\n",
        "      }\n",
        "  else:\n",
        "    bboxes = {}\n",
        "    for i, bbox in enumerate(bbox_dict):\n",
        "      x,y,w,h = int(bbox_dict[i]['x']*image_w), int(bbox_dict[i]['y']*image_h), int(bbox_dict[i]['w']*image_w), int(bbox_dict[i]['h']*image_h)\n",
        "      bboxes[i] = {\n",
        "          'area': x*y,\n",
        "          'x_offset': abs(x-image_w/2),\n",
        "          'y_offset': abs(y-image_h/2),\n",
        "          'bbox': str({'x': x,'y': y,'w': w,'h': h})\n",
        "      }\n",
        "    bboxes_df = pd.DataFrame.from_dict(bboxes, orient='index')\n",
        "    if (bboxes_df['area'].idxmax() == bboxes_df['x_offset'].idxmin() == bboxes_df['y_offset'].idxmin()):\n",
        "      i = bboxes_df['area'].idxmax()\n",
        "      main_bbox = ast.literal_eval(bboxes_df.iloc[[i]]['bbox'].values[0])\n",
        "    elif (bboxes_df['x_offset'].idxmin() == bboxes_df['y_offset'].idxmin()):\n",
        "      i = bboxes_df['x_offset'].idxmin()\n",
        "      main_bbox = ast.literal_eval(bboxes_df.iloc[[i]]['bbox'].values[0])\n",
        "      print(f'{image_id} is a little ambiguous for which is the main WBC. Main bbox chosen based on centering to be:')\n",
        "      print(main_bbox)\n",
        "      omit_count[wbc]['ambiguous']+=1\n",
        "    else:\n",
        "      print(f'{image_id} is omitted. This is too ambiguous to determine.')\n",
        "      omit_count[wbc]['omitted']+=1\n",
        "      return None\n",
        "\n",
        "  # This sets the x bounds and y bounds for cropping\n",
        "  x,y,w,h = int(main_bbox['x']), int(main_bbox['y']), int(main_bbox['w']), int(main_bbox['h'])\n",
        "  w=h=max(w,h) # We want square crops that include the whole WBC\n",
        "  x_i, x_f, y_i, y_f  = x-w/2, x+w/2, y-h/2, y+h/2\n",
        "\n",
        "  # If a square bounding box reaches outside the image, this will shift the limits back into the image\n",
        "  if x_i<0:\n",
        "    x_f = x_f-x_i\n",
        "    x_i = 0\n",
        "  if x_f>image_w:\n",
        "    x_i = x_i-(x_f-image_w)\n",
        "    x_f = image_w\n",
        "  if y_i<0:\n",
        "    y_f = y_f-y_i\n",
        "    y_i = 0\n",
        "  if y_f>image_h:\n",
        "    y_i = y_i-(y_f-image_h)\n",
        "    y_f = image_h\n",
        "\n",
        "  # Crops the image with final dimensions\n",
        "  crop_img=image_array[int(y_i):int(y_f), int(x_i):int(x_f)]\n",
        "  try:\n",
        "    im = PIL.Image.fromarray(crop_img)\n",
        "    im = im.resize((224,224))\n",
        "    return im\n",
        "  except:\n",
        "    print(f'{image_id} was omitted, there was an error cropping.')\n"
      ],
      "metadata": {
        "id": "txKXx_NXG5DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wbc_type = ['basophil', 'eosinophil', 'erythroblast', 'ig', 'lymphocyte', 'monocyte', 'neutrophil', 'platelet']\n",
        "root = '/content/runs/detect/'\n",
        "# For each white blood cell\n",
        "\n",
        "omit_count = {\n",
        "    'basophil': {\n",
        "        'ambiguous': 0,\n",
        "        'omitted': 0\n",
        "        },\n",
        "    'eosinophil':{\n",
        "        'ambiguous': 0,\n",
        "        'omitted': 0\n",
        "        },\n",
        "    'erythroblast':{\n",
        "        'ambiguous': 0,\n",
        "        'omitted': 0\n",
        "        },\n",
        "    'ig':{\n",
        "        'ambiguous': 0,\n",
        "        'omitted': 0\n",
        "        },\n",
        "    'lymphocyte':{\n",
        "        'ambiguous': 0,\n",
        "        'omitted': 0\n",
        "        },\n",
        "    'monocyte':{\n",
        "        'ambiguous': 0,\n",
        "        'omitted': 0\n",
        "        },\n",
        "    'neutrophil':{\n",
        "        'ambiguous': 0,\n",
        "        'omitted': 0\n",
        "        },\n",
        "    'platelet':{\n",
        "        'ambiguous': 0,\n",
        "        'omitted': 0\n",
        "        },\n",
        "}\n",
        "\n",
        "for wbc in wbc_type:\n",
        "  os.makedirs(f'/content/runs/cropped/{wbc}')\n",
        "  path = os.path.join(root, wbc+\"/exp/labels/\")\n",
        "  for filename in os.listdir(path):\n",
        "    with open(os.path.join(root, wbc+\"/exp/labels/\", filename)) as file:\n",
        "      df = pd.read_csv(file, \n",
        "                       delim_whitespace=True, \n",
        "                       header = None,\n",
        "                       names =['category_id', 'x', 'y', 'w', 'h'])\n",
        "      image_id = filename.rstrip('.txt')\n",
        "      df['image_id'] = image_id\n",
        "      bbox_dict = df.to_dict('records')\n",
        "      im = single_crop(bbox_dict, wbc)\n",
        "      if im:\n",
        "        im.save(f'/content/runs/cropped/{wbc}/{image_id}.png') # File naming is {image_id}\n",
        "      else:\n",
        "        print(f'This image was not saved')"
      ],
      "metadata": {
        "id": "Nx8H7GeVF5Ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.DataFrame.from_dict(omit_count).to_markdown())"
      ],
      "metadata": {
        "id": "CQZZ1YkopHqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r '/content/runs.zip' '/content/runs'"
      ],
      "metadata": {
        "id": "kFqNRBW67BL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cropping out Images (Size Considered)\n",
        "\n",
        "Only using images that have 1 WBC inside to avoid ambiguity. "
      ],
      "metadata": {
        "id": "ot0jb1nRfWav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmtree('/content/runs/cropped')"
      ],
      "metadata": {
        "id": "JgT1XBmZkqJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wbc_type = ['basophil', 'eosinophil', 'erythroblast', 'ig', 'lymphocyte', 'monocyte', 'neutrophil', 'platelet']\n",
        "root = '/content/runs/detect/'\n",
        "# For each white blood cell\n",
        "\n",
        "total_wbc = []\n",
        "counter = 0\n",
        "for wbc in wbc_type:\n",
        "  os.makedirs(f'/content/runs/cropped/{wbc}')\n",
        "  path = os.path.join(root, wbc+\"/exp/labels/\")\n",
        "  for filename in os.listdir(path):\n",
        "    with open(os.path.join(root, wbc+\"/exp/labels/\", filename)) as file:\n",
        "      df = pd.read_csv(file, \n",
        "                       delim_whitespace=True, \n",
        "                       header = None,\n",
        "                       names =['category_id', 'x', 'y', 'w', 'h'])\n",
        "      # Pick only detected cells that are WBC\n",
        "      wbc_df = df[df.category_id == 2].copy()\n",
        "      image_id = filename.rstrip('.txt')\n",
        "      wbc_df['image_id'] = image_id\n",
        "      wbc_df['wbc_type'] = wbc\n",
        "      bbox_dict = wbc_df.to_dict('records')\n",
        "      # Omit images that have more than one WBC in it\n",
        "      if wbc_df.shape[0] == 1:\n",
        "        total_wbc = total_wbc + bbox_dict\n",
        "      else:\n",
        "        counter += 1"
      ],
      "metadata": {
        "id": "zhHOaVvSh_oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find maximum bounding box. It seems like al"
      ],
      "metadata": {
        "id": "CxPLH_fVuWSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_wbc_df = pd.DataFrame(total_wbc)\n",
        "total_wbc_df['x'].idxmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJO7SbP0uVYu",
        "outputId": "2572806a-4fca-42ab-996c-aac05a1b2364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1750"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_wbc_df.iloc[1750]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOSKYisavE9p",
        "outputId": "9acc01e3-5260-4b48-b909-40774e497c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category_id             2\n",
              "x                0.884722\n",
              "y                0.333333\n",
              "w                   0.225\n",
              "h                0.275482\n",
              "image_id        EO_664204\n",
              "wbc_type       eosinophil\n",
              "Name: 1750, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_wbc_df['y'].idxmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuFv4vCzu7rF",
        "outputId": "bac38a94-a393-46f9-d329-bb493fa21c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10289"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_wbc_df.iloc[10289]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul5eff9MvaQI",
        "outputId": "3da23091-dbdf-4d37-84c4-422ac322e90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category_id            2\n",
              "x               0.368056\n",
              "y               0.966942\n",
              "w               0.302778\n",
              "h               0.066116\n",
              "image_id       MO_363879\n",
              "wbc_type        monocyte\n",
              "Name: 10289, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, bbox_dict in enumerate(total_wbc):\n",
        "  image_id = total_wbc[i]['image_id']\n",
        "  wbc = total_wbc[i]['wbc_type']\n",
        "  image = PIL.Image.open(f'/content/PBC_dataset_normal_DIB/{wbc}/{image_id}.jpg')\n",
        "  image_array = np.array(image)\n",
        "  crop_img = image_array[0:360, 0:360]\n",
        "  try:\n",
        "    im = PIL.Image.fromarray(crop_img)\n",
        "    im = im.resize((224,224))\n",
        "  except:\n",
        "    print(f'{image_id} was omitted, there was an error cropping.')\n",
        "  if im:\n",
        "    im.save(f'/content/runs/PBC_cropped/{wbc}/{image_id}.png') # File naming is {image_id}\n",
        "  else:\n",
        "    print(f'This image was not saved')"
      ],
      "metadata": {
        "id": "ABeZrJuQtjjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r '/content/PBC_dataset_nomal_DIB_cropped_224_size_considered.zip' '/content/runs/cropped'"
      ],
      "metadata": {
        "id": "gl9M1VPk5_sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Determine the average size of RBC within the dataset.\n",
        "\n",
        "We use object detection YOLOv5 inference to detect all RBC within the Acevedo dataset. We then take the root mean of the sum of areas of RBC within the dataset."
      ],
      "metadata": {
        "id": "Gy4w60PjbkKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs YOLOv5s and stores all annotations as text\n",
        "wbc_type = ['basophil', 'eosinophil', 'erythroblast', 'ig', 'lymphocyte', 'monocyte', 'neutrophil', 'platelet']\n",
        "for wbc in wbc_type:\n",
        "  !python /content/yolov5/detect.py --source /content/PBC_dataset_normal_DIB/{wbc} --weights \"/content/4-01-2022-artemis.pt\" --save-txt --project runs/detect/{wbc} --classes 1 --nosave --exist-ok"
      ],
      "metadata": {
        "id": "DFVDexG7achS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "rbc_sizes_acevedo = []\n",
        "root = '/content/runs/detect'\n",
        "\n",
        "image_w = 360\n",
        "image_h = 363\n",
        "\n",
        "for wbc in wbc_type:\n",
        "  path = os.path.join(root, wbc+\"/exp/labels/\")\n",
        "  for filename in os.listdir(path):\n",
        "    with open(os.path.join(root, wbc+\"/exp/labels/\", filename)) as file:\n",
        "      df = pd.read_csv(file, \n",
        "                       delim_whitespace=True, \n",
        "                       header = None,\n",
        "                       names =['category_id', 'x', 'y', 'w', 'h'])\n",
        "      rbc_df = df.loc[df['category_id'] == 1].copy()\n",
        "      rbc_df[\"area\"] = rbc_df[\"w\"] * image_w * rbc_df[\"h\"] * image_h\n",
        "      rbc_sizes_acevedo = rbc_sizes_acevedo + rbc_df[\"area\"].tolist()\n",
        "      "
      ],
      "metadata": {
        "id": "87IlFWS8bsHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(rbc_sizes_acevedo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA4qogb_VOt2",
        "outputId": "0d41de4b-c37f-457f-e486-751c7a8e4b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1209201983.423902"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = math.sqrt(sum(rbc_sizes_acevedo)/len(rbc_sizes_acevedo))"
      ],
      "metadata": {
        "id": "XniauNSUk3nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1"
      ],
      "metadata": {
        "id": "KTrZSJ_W5aYG",
        "outputId": "6b19acdd-c057-4647-bc74-c969fdb59ea4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68.78754078932712"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like the RBC size distribution is relatively tight, indicating the images in Acevedo dataset are likely all the same in magnification."
      ],
      "metadata": {
        "id": "0OX77KSRljFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(np.sqrt(rbc_sizes_acevedo))\n",
        "plt.axvline(r1, color='r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6q8WrNYakWua",
        "outputId": "85c7e466-3faf-45c8-f7ce-7c16a0c2eecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7f7be913b550>"
            ]
          },
          "metadata": {},
          "execution_count": 188
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZdINBXozNg-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resizing\n",
        "\n",
        "**DO NOT RUN CODE**\n",
        "\n",
        "This was code that converted all the images to 224 size however that has now been implemented during cropping above."
      ],
      "metadata": {
        "id": "k_Jw-OrfM5e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/BCCD_cropped_wbc_classified_test_set.zip'"
      ],
      "metadata": {
        "id": "rTB3r3iCDQUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "search_directory = '/content/BCCD_cropped_wbc_classified_test_set'\n",
        "image_files = []\n",
        "for root, dirs, files in os.walk(search_directory):\n",
        "  for file in tqdm(files):\n",
        "    if (file.endswith(\".png\") or file.endswith('.PNG')):\n",
        "      im = Image.open(os.path.join(root, file))\n",
        "      im_resized = im.resize((224,224))\n",
        "      im_resized.save(os.path.join(root, file))\n"
      ],
      "metadata": {
        "id": "ZoTcHRk9EBee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8817d50f-4a94-485a-a545-aa481449c8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 257/257 [00:07<00:00, 32.18it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 26.65it/s]\n",
            "100%|██████████| 36/36 [00:00<00:00, 40.84it/s]\n",
            "100%|██████████| 57/57 [00:01<00:00, 31.29it/s]\n",
            "100%|██████████| 21/21 [00:00<00:00, 30.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r '/content/BCCD_cropped_wbc_classified_test_set.zip' '/content/BCCD_cropped_wbc_classified_test_set'"
      ],
      "metadata": {
        "id": "QztxeN2SL-ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/PBC_dataset_nomal_DIB_cropped_224_size_considered.zip /content/drive/MyDrive/Colab\\ Notebooks"
      ],
      "metadata": {
        "id": "QehX-m0CMjZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crop out WBC from Blood Films"
      ],
      "metadata": {
        "id": "xDBv161WANsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs YOLOv5s and stores all annotations as text\n",
        "source_path = '/content/Blood_Film_Cases'\n",
        "save_path = '/content/yolov5/runs/detect/'\n",
        "cases = next(os.walk(source_path))[1]\n",
        "\n",
        "#for root, path, files in os.walk(image_path):\n",
        "#  print(root, path, file)\n",
        "for case in cases:\n",
        "  image_path = os.path.join(source_path, case, '40x')\n",
        "  label_path = os.path.join(save_path, case)\n",
        "  !python /content/yolov5/detect.py --source {image_path} --weights \"/content/4-01-2022-artemis.pt\" --save-txt --project {label_path} --classes 2 --nosave --exist-ok"
      ],
      "metadata": {
        "id": "MGJAUw0YKllU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crop out WBC from RPA Blood Films\n"
      ],
      "metadata": {
        "id": "07ziOtaLgg9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Determine the average size of RBC within the dataset."
      ],
      "metadata": {
        "id": "3gvszaYG34cD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are finding the average size of RBC in these custom RPA blood films (R2). Earlier we found the average size of RBC in the training data (R1). Using both, we can figure out the ratio of RBC sizes i.e. R2/R1. "
      ],
      "metadata": {
        "id": "dhZ3btCIkUdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import rmtree\n",
        "rmtree('/content/Output')"
      ],
      "metadata": {
        "id": "vIUdruGab4AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  '/content/drive/MyDrive/Colab Notebooks/RPA Blood Film Labels (Crude Labels).zip'"
      ],
      "metadata": {
        "id": "h53UlD62aTbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/RPA Blood Film Labels (Crude Labels)'\n",
        "\n",
        "rbc_sizes_RPA = []\n",
        "\n",
        "image_w = 2448\n",
        "image_h = 1920\n",
        "\n",
        "for filename in os.listdir(file_path):\n",
        "  with open(os.path.join(file_path, filename)) as file:\n",
        "    df = pd.read_csv(file, \n",
        "      delim_whitespace=True, \n",
        "      header = None,\n",
        "      names =['category_id', 'x', 'y', 'w', 'h'])\n",
        "    rbc_df = df.loc[df['category_id'] == 2].copy()\n",
        "    rbc_df[\"area\"] = rbc_df[\"w\"] * image_w * rbc_df[\"h\"] * image_h\n",
        "    rbc_sizes_RPA = rbc_sizes_RPA + rbc_df[\"area\"].tolist()"
      ],
      "metadata": {
        "id": "oqMrF1a3glng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(rbc_sizes_RPA)"
      ],
      "metadata": {
        "id": "IrlMJkcLkSMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7429b76d-4588-43c9-b4b2-5607507b6f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22570615.887289412"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = math.sqrt(sum(rbc_sizes_RPA)/len(rbc_sizes_RPA))"
      ],
      "metadata": {
        "id": "YvUpfMjTlawt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsAqp4u0eybB",
        "outputId": "0c77dcea-5499-4113-c116-410bb453b258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137.6625545113873"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like the RBC size distribution is relatively tight, indicating the images in RPA dataset are likely all the same in magnification."
      ],
      "metadata": {
        "id": "Kea0Ques64qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(np.sqrt(rbc_sizes_RPA))\n",
        "plt.axvline(r2, color='r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "uDWpBnqh6tJU",
        "outputId": "c56755b7-0937-4b3f-9d7d-0cee274d50af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7f7beae6fe50>"
            ]
          },
          "metadata": {},
          "execution_count": 187
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ratio of RBC Sizes"
      ],
      "metadata": {
        "id": "NIHo21vge2ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rbc_ratio = r2/r1\n",
        "rbc_ratio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VGWDrrre7Lj",
        "outputId": "28c9f97f-5bdf-48e5-a67d-54af6bbf0853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0012716391911867"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cropping out Images (Size Considered)"
      ],
      "metadata": {
        "id": "DV6THoTV39yt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The original cropping size for images used in training the classifier was 360px by 360 px. The r1 i.e. average root-mean RBC Area in Acevedo dataset is `r1 = 0.1902852917455713` "
      ],
      "metadata": {
        "id": "z44qhLj-4DmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crop_length = math.sqrt(rbc_ratio*360*360)"
      ],
      "metadata": {
        "id": "amhaxmBr5dfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crop_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HbNYW03MUbc",
        "outputId": "9b2bb2d6-b492-4639-f72d-8fd50d521797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "509.27870998027964"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually modify to 350 to fit size."
      ],
      "metadata": {
        "id": "Zhf2cp2lSDXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crop_length = 350"
      ],
      "metadata": {
        "id": "_uSyImqLQcMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/RPA Blood Film Labels (Specific Labels).zip'"
      ],
      "metadata": {
        "id": "OpmK-oC48H7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/RPA Blood Film Images.zip'"
      ],
      "metadata": {
        "id": "MwjhLtiaAOAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmtree('/content/runs/RPA_cropped')"
      ],
      "metadata": {
        "id": "Fo4snVexGZLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_file_path = '/content/RPA Blood Film Labels (Specific Labels)'\n",
        "image_file_path = '/content/RPA Blood Film Images'\n",
        "\n",
        "wbc_names = {\n",
        "    0: 'platelet',\n",
        "    1: 'rbc',\n",
        "    2: 'neutrophil',\n",
        "    3: 'eosinophil',\n",
        "    4: 'lymphocyte',\n",
        "    5: 'monocyte',\n",
        "    6: 'basophil',\n",
        "    7: 'myelocyte',\n",
        "    8: 'promyelocyte',\n",
        "    9: 'blast',\n",
        "    10: 'erythroblast'\n",
        "}\n",
        "\n",
        "total_wbc = []\n",
        "\n",
        "os.makedirs('/content/runs/RPA_cropped/')\n",
        "for value in wbc_names.values():\n",
        "  os.makedirs(f'/content/runs/RPA_cropped/{value}')\n",
        "\n",
        "for filename in os.listdir(label_file_path):\n",
        "  with open(os.path.join(label_file_path, filename)) as file:\n",
        "    df = pd.read_csv(file, \n",
        "      delim_whitespace=True, \n",
        "      header = None,\n",
        "      names =['category_id', 'x', 'y', 'w', 'h'])\n",
        "    image_id = filename.rstrip('.txt')\n",
        "    wbc_df = df.loc[df['category_id'] != 1].copy()\n",
        "    bbox_dict = wbc_df.to_dict('records')\n",
        "\n",
        "\n",
        "    # Open image to crop\n",
        "    image = PIL.Image.open(os.path.join(image_file_path, f'{image_id}.jpg'))\n",
        "    image_w, image_h = image.size\n",
        "    image_array = np.array(image)\n",
        "\n",
        "    for i, bbox in enumerate(bbox_dict):\n",
        "      x, y = int(bbox['x']*image_w), int(bbox['y']*image_h)\n",
        "      category_id = bbox['category_id']\n",
        "      # Crop using adjusted crop size based on RBC ratio\n",
        "      x_i, x_f, y_i, y_f  = x-crop_length/2, x+crop_length/2, y-crop_length/2, y+crop_length/2\n",
        "      crop_img = image_array[int(y_i):int(y_f), int(x_i):int(x_f)]\n",
        "      try:\n",
        "        im = PIL.Image.fromarray(crop_img)\n",
        "        im = im.resize((224,224))\n",
        "        if im:\n",
        "            im.save(f'/content/runs/RPA_cropped/{wbc_names[category_id]}/{image_id}_{i}.png') # File naming is {image_id}_{i} where i is WBC in image\n",
        "      except:\n",
        "        print(f'Can\\'t crop WBC {i} from image with image_id {image_id}')"
      ],
      "metadata": {
        "id": "GKlNx3q67XQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r '/content/RPA_cropped_wbc_classified.zip' '/content/runs/RPA_cropped'"
      ],
      "metadata": {
        "id": "gHOKfAQHS62l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/RPA_cropped_wbc_classified.zip /content/drive/MyDrive/Colab\\ Notebooks"
      ],
      "metadata": {
        "id": "eHwpx8RSTJPz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}